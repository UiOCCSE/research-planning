<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="description" content="Project outline for computational assessment">

<title>Project outline for computational assessment</title>


<link href="https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_styles/style_solarized_box/css/solarized_light_code.css" rel="stylesheet" type="text/css" title="light"/>
<script src="https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_styles/style_solarized_box/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<link href="http://thomasf.github.io/solarized-css/solarized-light.min.css" rel="stylesheet">
<style type="text/css">
h1 {color: #b58900;}  /* yellow */
/* h1 {color: #cb4b16;}  orange */
/* h1 {color: #d33682;}  magenta, the original choice of thomasf */
code { padding: 0px; background-color: inherit; }
pre {
  border: 0pt solid #93a1a1;
  box-shadow: none;
}

div { text-align: justify; text-justify: inter-word; }
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Assessing Computational Understanding in Physics',
               2,
               None,
               '___sec0'),
              ('Assessing Computational Understanding in Physics',
               2,
               None,
               '___sec1'),
              ('Principles of Development', 2, None, '___sec2'),
              ('Principles of Development', 2, None, '___sec3'),
              ('Principles of Development', 2, None, '___sec4'),
              ('Principles of Development', 2, None, '___sec5'),
              ('Principles of Development', 2, None, '___sec6'),
              ('Principles of Development', 2, None, '___sec7'),
              ('Project Details', 2, None, '___sec8'),
              ('Project Details', 2, None, '___sec9'),
              ('Project Details', 2, None, '___sec10'),
              ('Project Details', 2, None, '___sec11'),
              ('Project Details', 2, None, '___sec12'),
              ('Project Details', 2, None, '___sec13'),
              ('Project Details', 2, None, '___sec14'),
              ('Project Details', 2, None, '___sec15'),
              ('Project Timeline', 2, None, '___sec16'),
              ('Project Timeline', 2, None, '___sec17'),
              ('Project Timeline', 2, None, '___sec18'),
              ('Project Timeline', 2, None, '___sec19'),
              ('Project Timeline', 2, None, '___sec20'),
              ('Project Timeline', 2, None, '___sec21'),
              ('Proposed Project Resources', 2, None, '___sec22')]}
end of tocinfo -->

<body>

    
<!-- ------------------- main content ---------------------- -->



<center><h1>Project outline for computational assessment</h1></center>  <!-- document title -->

<p>
<!-- author(s): Danny Caballero -->

<center>
<b>Danny Caballero</b> [1, 2]
</center>

<p>
<!-- institution(s) -->

<center>[1] <b>Michigan State University</b></center>
<center>[2] <b>University of Oslo</b></center>
<br>
<p>
<center><h4>April 1, 2017</h4></center> <!-- date -->
<br>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec0">Assessing Computational Understanding in Physics </h2>

<p>
<b>Rationale</b>

<ul>
<li> Systematic measurement of student understanding is essential for evaluating movement towards more computational instruction</li>
<li> Partners (i.e., PICUP and faculty collaborators) are grokking for some form of systematic assessment in specific classes</li>
<li> Assessments can help drive further research investigations including comparative and longitudinal studies</li>
<li> The development of these assessments can lead to high visibility of the centre</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec1">Assessing Computational Understanding in Physics </h2>

<p>
<b>Product</b>

<ul>
<li> A suite of assessments of computational understanding in physics that are:</li>

<ul>
  <li> developed for specific courses, yet broadly applicable,</li>
  <li> informed by observed student understanding,</li>
  <li> grounded in faculty-articulated learning goals,</li>
  <li> developed using strong theoretical grounding and methodology, and</li>
  <li> deployed in a centralized way to facilitate community-level research.</li>
</ul>

</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec2">Principles of Development </h2>

<ul>
<li> Course-specific</li>
<li> Broad applicability</li>
<li> Informative about student understanding</li>
<li> Informative to and valuable for faculty</li>
<li> Strong theoretical basis for design and measurement</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec3">Principles of Development </h2>

<p>
<b>Course-specific</b>

<ul>
<li> Goals for including computation and thus assessments are tied to specific learning outcomes for courses</li>
<li> Course content is one such aspect, but others include the expectation of more advanced and deeper understandings of the same algorithms and tools</li>
<li> As different courses vary in their depth and focus, overlapping course content should be evaluated (lowest-common denominator assessment)</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec4">Principles of Development </h2>

<p>
<b>Broad applicability</b>

<ul>
<li> Assessments developed for specific courses should emphasize common content and topics (i.e., overlapping learning goals)</li>
<li> Broader applicability of the assessments will lead to broader use of the assessments</li>
<li> Can support developing a wealth of understanding about implementation and demographic effects</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec5">Principles of Development </h2>

<p>
<b>Informative about student understandings</b>

<ul>
<li> Assessments should provide information beyond the percentage of students answering correctly</li>
<li> Selected assessment stems should provide information about what understandings students are holding in the moment</li>
<li> Stems should be drawn from expressed understandings of students</li>
<li> Validation of the assessments must include discussion with students</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec6">Principles of Development </h2>

<p>
<b>Informative to and valuable for faculty</b>

<ul>
<li> As such assessments are meant to inform faculty about changes made to their won courses, these assessment development must involve faculty</li>
<li> Learning outcomes that will be evaluated must be drawn from faculty teaching specific courses</li>
<li> Validation of the assessments must include discussion with faculty</li>
<li> Centralized deployment and analysis can ensure minimal impact on faculty time</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec7">Principles of Development </h2>

<p>
<b>Theoretical and Methodological Grounding</b>

<ul>
<li> Interviews with students and faculty will explore the variation in understanding and faculty learning goals (Phenomenographic and conceptual approach)</li>
<li> Continuous validation of items against student understanding and faculty learning goals as assessments are constructed</li>
<li> Assessment design will make use of appropriate measurement theory (Rasch model)</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec8">Project Details </h2>

<p>
<b>Key Project Elements</b>

<p>
For a given assessment, we will:

<ul>
<li> Interview faculty about their goals for teaching computation and from what experiences those goals are derived (<b>Faculty Goal Interviews</b>)</li>
<li> Interview students about their computational understandings (<b>Student Understanding Interviews</b>)</li>
<li> Develop a preliminary assessment of student understanding informed by faculty goals and categories of student understanding (<b>Assessment Construction</b>)</li>
<li> Validate the assessment through discussion with faculty, interviews with students, and the use of Rasch modeling on specific items (<b>Validation Interiews</b> and <b>Rasch Analysis</b>)</li>
<li> Deploy the assessment in relevant contexts (<b>Evaluation and Further Studies</b>)</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec9">Project Details </h2>

<p>
<b>Faculty Goal Interviews</b>

<ul>
<li> Interview faculty about their computational experiences and how those experiences lead them to think about what students should "get out of" their computational experiences in a specific class</li>
<li> Develop the outcome space for these interviews, which is likely to include computational learning goals</li>
<li> Categories of faculty computational experiences and how those relate to what their students should learn is the overarching research</li>
<li> Computational learning goals derived from these interviews help form the basis for assessment development</li>
</ul>

<b>Possible Papers</b>

<ul>
<li> AJP article  - faculty learning goals for computation</li>
<li> PR-PER article - phenomenongraphic study of faculty computational experiences and their relation to computational learning goals</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec10">Project Details </h2>

<p>
<b>Student Understanding Interviews</b>

<ul>
<li> Interview students about their computational understanding</li>
<li> Develop categories of students' computational understanding</li>
<li> Reported computational difficulties help form the basis for assessment development</li>
</ul>

<b>Possible Papers</b>

<ul>
<li> AJP article - reported computational difficulties</li>
<li> PR-PER article - detailed results conceptual interview of students around computational understanding</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec11">Project Details </h2>

<p>
<b>Assessment Construction</b>

<ul>
<li> Development of assessment informed by faculty goals and student understandings</li>
<li> Development of web framework for deployment and analysis of assessment</li>
<li> Pilot testing with students to check further develop initial framework</li>
</ul>

<b>Possible Papers</b>

<ul>
<li> Some Ed Tech article - centralized assessment of computational understanding</li>
<li> PERC paper - Initial assessment development from goals and understandings</li>
<li> PERC paper - Results of pilot testing and changes made</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec12">Project Details </h2>

<p>
<b>Validation Interviews</b>

<ul>
<li> Interview faculty to validate preliminary assessment</li>
<li> Interview students to validate wording and what meaning can be made from answers</li>
<li> Make alterations as needed</li>
</ul>

<b>Possible Papers</b>

<ul>
<li> PERC paper - Discussion of changes made to assessment based on interviews</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec13">Project Details </h2>

<p>
<b>Rasch Analysis</b>

<ul>
<li> Pilot assessment with partners</li>
<li> Perform analysis using Rasch tools developed for the assessment and web framework</li>
<li> Continued use of assessment and validation with Rasch analysis</li>
</ul>

<b>Possible Papers</b>

<ul>
<li> PR-PER article - Use of Rasch analysis to develop assessment; detailed analysis of questions and choices made</li>
<li> PR-PER article - presentation of the assessment and its development</li>
<li> AJP article - presentation of assessment and important results</li>
<li> Some Ed Tech article - how Rasch analysis is used and deployed in web framework for assessment</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec14">Project Details </h2>

<p>
<b>Evaluation and Further Studies</b>

<ul>
<li> Demographic and Cross-institutional analysis of existing data</li>
<li> Cross-sectional and longitudinal studies</li>
<li> Comparative students</li>
</ul>

PR-PER and AJP articles - as completed

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec15">Project Details </h2>

<p>
<b>Necessary technological supports</b>

<p>
In order to perform analysis and deploy (and score) the assessment in a centralized manner, we will need to:

<ul>
<li> develop a set of open-source tools for Rasch analysis (e.g., using Python),</li>
<li> develop a web framework for the construction and deployment of assessments (e.g., using devilry and additional tools),</li>
<li> develop a set of open-source analysis tools that generate reports for faculty (e.g., devilry, doconce, and additional tools), and</li>
<li> develop a set of open-source analysis tools that allow us to answer broader questions by pooling data across faculty users.</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec16">Project Timeline </h2>

<ul>
<li> <b>Semester 1:</b></li>

<ul>
  <li> Develop protocol for faculty and student interviews</li>
  <li> Interview students and faculty</li>
</ul>

</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec17">Project Timeline </h2>

<ul>
<li> <b>Semester 2:</b></li>

<ul>
  <li> Perform analysis of faculty and student interviews</li>
  <li> Identify faculty goals and preliminary categories of student understanding</li>
  <li> Continue phenomenographic analysis of faculty and student interviews</li>
</ul>

</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec18">Project Timeline </h2>

<ul>
<li> <b>Semester 3:</b></li>

<ul>
  <li> Develop preliminary assessment questions</li>
  <li> Validate assessment with faculty and student interviews</li>
  <li> Identify partners for initial data collection</li>
  <li> Continue phenomenographic analysis of faculty and student interviews</li>
  <li> Begin development of web framework for delivery and analysis</li>
</ul>

</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec19">Project Timeline </h2>

<ul>
<li> <b>Semester 4:</b></li>

<ul>
  <li> Pilot assessment with partners</li>
  <li> Obtain feedback on usage</li>
  <li> Perform Rasch analysis on preliminary data to identify assessment items to review</li>
  <li> Alter problematic items as needed</li>
  <li> Revalidate assessment with student and faculty as needed</li>
  <li> Continue to identify partners</li>
  <li> Complete phenomenographic analysis of faculty and student interviews</li>
</ul>

</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec20">Project Timeline </h2>

<ul>
<li> <b>Semester 5:</b></li>

<ul>
  <li> Launch second pilot assessment with partners using updated web framework, assessment, and analysis tools</li>
  <li> Perform Rasch analysis on second round of data to identify assessment items to review</li>
  <li> Alter problematic items as needed</li>
  <li> Revalidate assessment with student and faculty as needed</li>
  <li> Continue to identify partners</li>
  <li> Develop tools for cross-institutional and demographic analysis</li>
  <li> Begin preliminary investigation of cross-institutional and demographic effects</li>
</ul>

</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec21">Project Timeline </h2>

<ul>
<li> <b>Semester 6:</b></li>

<ul>
  <li> Launch near final assessment with partners using updated web framework, assessment, and analysis tools</li>
  <li> Perform Rasch analysis on second round of data to identify assessment items to review</li>
  <li> Alter problematic items as needed</li>
  <li> Revalidate assessment with student and faculty as needed</li>
  <li> Perform cross-institutional and demographic analyses</li>
  <li> <b>Finalized assessment completed by end of semester</b></li>
</ul>

</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec22">Proposed Project Resources </h2>

<ul>
<li> Danny Caballero</li>
<li> Postdoc (to lead on project - need PER background)</li>
<li> PhD student 1 (PER with qualitative emphasis) - Dissertation: Categories of faculty's computational goals and student computational understandings for course X</li>
<li> PhD student 2 (PER with quantitative emphasis) - Dissertation: Development of assessment of students' computational understanding in course X</li>
<li> Master's students (PER, Computational, Web) - Projects: Development and deployment of analysis tools, web framework, testing usability, etc.</li>
</ul>


<!-- ------------------- end of main content --------------- -->


</body>
</html>
    

