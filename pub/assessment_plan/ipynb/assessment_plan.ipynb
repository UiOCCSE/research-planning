{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: Project outline for computational assessment -->\n",
    "# Project outline for computational assessment\n",
    "<!-- dom:AUTHOR: Danny Caballero at Michigan State University & University of Oslo -->\n",
    "<!-- Author: -->  \n",
    "**Danny Caballero**, Michigan State University and University of Oslo\n",
    "\n",
    "Date: **April 1, 2017**\n",
    "\n",
    "## Assessing Computational Understanding in Physics\n",
    "\n",
    "**Rationale**\n",
    "\n",
    "* Systematic measurement of student understanding is essential for evaluating movement towards more computational instruction\n",
    "\n",
    "* Partners (i.e., PICUP and faculty collaborators) are grokking for some form of systematic assessment in specific classes\n",
    "\n",
    "* Assessments can help drive further research investigations including comparative and longitudinal studies\n",
    "\n",
    "* The development of these assessments can lead to high visibility of the centre\n",
    "\n",
    "## Assessing Computational Understanding in Physics\n",
    "\n",
    "**Product**\n",
    "\n",
    "* A suite of assessments of computational understanding in physics that are:\n",
    "\n",
    "  * developed for specific courses, yet broadly applicable,\n",
    "\n",
    "  * informed by observed student understanding,\n",
    "\n",
    "  * grounded in faculty-articulated learning goals,\n",
    "\n",
    "  * developed using strong theoretical grounding and methodology, and\n",
    "\n",
    "  * deployed in a centralized way to facilitate community-level research.\n",
    "\n",
    "\n",
    "## Principles of Development\n",
    "\n",
    "* Course-specific\n",
    "\n",
    "* Broad applicability\n",
    "\n",
    "* Informative about student understanding\n",
    "\n",
    "* Informative to and valuable for faculty\n",
    "\n",
    "* Strong theoretical basis for design and measurement\n",
    "\n",
    "## Principles of Development\n",
    "\n",
    "**Course-specific**\n",
    "\n",
    "* Goals for including computation and thus assessments are tied to specific learning outcomes for courses\n",
    "\n",
    "* Course content is one such aspect, but others include the expectation of more advanced and deeper understandings of the same algorithms and tools\n",
    "\n",
    "* As different courses vary in their depth and focus, overlapping course content should be evaluated (lowest-common denominator assessment)\n",
    "\n",
    "## Principles of Development\n",
    "\n",
    "**Broad applicability**\n",
    "\n",
    "* Assessments developed for specific courses should emphasize common content and topics (i.e., overlapping learning goals)\n",
    "\n",
    "* Broader applicability of the assessments will lead to broader use of the assessments\n",
    "\n",
    "* Can support developing a wealth of understanding about implementation and demographic effects\n",
    "\n",
    "## Principles of Development\n",
    "\n",
    "**Informative about student understandings**\n",
    "\n",
    "* Assessments should provide information beyond the percentage of students answering correctly\n",
    "\n",
    "* Selected assessment stems should provide information about what understandings students are holding in the moment\n",
    "\n",
    "* Stems should be drawn from expressed understandings of students\n",
    "\n",
    "* Validation of the assessments must include discussion with students\n",
    "\n",
    "## Principles of Development\n",
    "\n",
    "**Informative to and valuable for faculty**\n",
    "\n",
    "* As such assessments are meant to inform faculty about changes made to their won courses, these assessment development must involve faculty\n",
    "\n",
    "* Learning outcomes that will be evaluated must be drawn from faculty teaching specific courses\n",
    "\n",
    "* Validation of the assessments must include discussion with faculty\n",
    "\n",
    "* Centralized deployment and analysis can ensure minimal impact on faculty time\n",
    "\n",
    "## Principles of Development\n",
    "\n",
    "**Theoretical and Methodological Grounding**\n",
    "\n",
    "* Interviews with students and faculty will explore the variation in understanding and faculty learning goals (Phenomenographic and conceptual approach)\n",
    "\n",
    "* Continuous validation of items against student understanding and faculty learning goals as assessments are constructed\n",
    "\n",
    "* Assessment design will make use of appropriate measurement theory (Rasch model)\n",
    "\n",
    "## Project Details\n",
    "\n",
    "**Key Project Elements**\n",
    "\n",
    "For a given assessment, we will:\n",
    "* Interview faculty about their goals for teaching computation and from what experiences those goals are derived (**Faculty Goal Interviews**)\n",
    "\n",
    "* Interview students about their computational understandings (**Student Understanding Interviews**)\n",
    "\n",
    "* Develop a preliminary assessment of student understanding informed by faculty goals and categories of student understanding (**Assessment Construction**)\n",
    "\n",
    "* Validate the assessment through discussion with faculty, interviews with students, and the use of Rasch modeling on specific items (**Validation Interiews** and **Rasch Analysis**)\n",
    "\n",
    "* Deploy the assessment in relevant contexts (**Evaluation and Further Studies**)\n",
    "\n",
    "## Project Details\n",
    "\n",
    "**Faculty Goal Interviews**\n",
    "\n",
    "* Interview faculty about their computational experiences and how those experiences lead them to think about what students should \"get out of\" their computational experiences in a specific class\n",
    "\n",
    "* Develop the outcome space for these interviews, which is likely to include computational learning goals\n",
    "\n",
    "* Categories of faculty computational experiences and how those relate to what their students should learn is the overarching research\n",
    "\n",
    "* Computational learning goals derived from these interviews help form the basis for assessment development\n",
    "\n",
    "**Possible Papers**\n",
    "\n",
    "* AJP article  - faculty learning goals for computation\n",
    "\n",
    "* PR-PER article - phenomenongraphic study of faculty computational experiences and their relation to computational learning goals\n",
    "\n",
    "## Project Details\n",
    "\n",
    "**Student Understanding Interviews**\n",
    "\n",
    "* Interview students about their computational understanding\n",
    "\n",
    "* Develop categories of students' computational understanding\n",
    "\n",
    "* Reported computational difficulties help form the basis for assessment development\n",
    "\n",
    "**Possible Papers**\n",
    "\n",
    "* AJP article - reported computational difficulties\n",
    "\n",
    "* PR-PER article - detailed results conceptual interview of students around computational understanding\n",
    "\n",
    "## Project Details\n",
    "\n",
    "**Assessment Construction**\n",
    "\n",
    "* Development of assessment informed by faculty goals and student understandings\n",
    "\n",
    "* Development of web framework for deployment and analysis of assessment\n",
    "\n",
    "* Pilot testing with students to check further develop initial framework\n",
    "\n",
    "**Possible Papers**\n",
    "\n",
    "* Some Ed Tech article - centralized assessment of computational understanding\n",
    "\n",
    "* PERC paper - Initial assessment development from goals and understandings\n",
    "\n",
    "* PERC paper - Results of pilot testing and changes made\n",
    "\n",
    "## Project Details\n",
    "\n",
    "**Validation Interviews**\n",
    "\n",
    "* Interview faculty to validate preliminary assessment\n",
    "\n",
    "* Interview students to validate wording and what meaning can be made from answers\n",
    "\n",
    "* Make alterations as needed\n",
    "\n",
    "**Possible Papers**\n",
    "\n",
    "* PERC paper - Discussion of changes made to assessment based on interviews\n",
    "\n",
    "## Project Details\n",
    "\n",
    "**Rasch Analysis**\n",
    "\n",
    "* Pilot assessment with partners\n",
    "\n",
    "* Perform analysis using Rasch tools developed for the assessment and web framework\n",
    "\n",
    "* Continued use of assessment and validation with Rasch analysis\n",
    "\n",
    "**Possible Papers**\n",
    "\n",
    "* PR-PER article - Use of Rasch analysis to develop assessment; detailed analysis of questions and choices made\n",
    "\n",
    "* PR-PER article - presentation of the assessment and its development\n",
    "\n",
    "* AJP article - presentation of assessment and important results\n",
    "\n",
    "* Some Ed Tech article - how Rasch analysis is used and deployed in web framework for assessment\n",
    "\n",
    "## Project Details\n",
    "\n",
    "**Evaluation and Further Studies**\n",
    "\n",
    "* Demographic and Cross-institutional analysis of existing data\n",
    "\n",
    "* Cross-sectional and longitudinal studies\n",
    "\n",
    "* Comparative students\n",
    "\n",
    "PR-PER and AJP articles - as completed\n",
    "\n",
    "## Project Details\n",
    "\n",
    "**Necessary technological supports**\n",
    "\n",
    "In order to perform analysis and deploy (and score) the assessment in a centralized manner, we will need to:\n",
    "\n",
    "* develop a set of open-source tools for Rasch analysis (e.g., using Python),\n",
    "\n",
    "* develop a web framework for the construction and deployment of assessments (e.g., using devilry and additional tools),\n",
    "\n",
    "* develop a set of open-source analysis tools that generate reports for faculty (e.g., devilry, doconce, and additional tools), and\n",
    "\n",
    "* develop a set of open-source analysis tools that allow us to answer broader questions by pooling data across faculty users.\n",
    "\n",
    "## Project Timeline\n",
    "\n",
    "* **Semester 1:**\n",
    "\n",
    "  * Develop protocol for faculty and student interviews\n",
    "\n",
    "  * Interview students and faculty\n",
    "\n",
    "\n",
    "## Project Timeline\n",
    "\n",
    "* **Semester 2:**\n",
    "\n",
    "  * Perform analysis of faculty and student interviews\n",
    "\n",
    "  * Identify faculty goals and preliminary categories of student understanding\n",
    "\n",
    "  * Continue phenomenographic analysis of faculty and student interviews\n",
    "\n",
    "\n",
    "## Project Timeline\n",
    "\n",
    "* **Semester 3:**\n",
    "\n",
    "  * Develop preliminary assessment questions\n",
    "\n",
    "  * Validate assessment with faculty and student interviews\n",
    "\n",
    "  * Identify partners for initial data collection\n",
    "\n",
    "  * Continue phenomenographic analysis of faculty and student interviews\n",
    "\n",
    "  * Begin development of web framework for delivery and analysis\n",
    "\n",
    "\n",
    "## Project Timeline\n",
    "\n",
    "* **Semester 4:**\n",
    "\n",
    "  * Pilot assessment with partners\n",
    "\n",
    "  * Obtain feedback on usage\n",
    "\n",
    "  * Perform Rasch analysis on preliminary data to identify assessment items to review\n",
    "\n",
    "  * Alter problematic items as needed\n",
    "\n",
    "  * Revalidate assessment with student and faculty as needed\n",
    "\n",
    "  * Continue to identify partners\n",
    "\n",
    "  * Complete phenomenographic analysis of faculty and student interviews\n",
    "\n",
    "\n",
    "## Project Timeline\n",
    "\n",
    "* **Semester 5:**\n",
    "\n",
    "  * Launch second pilot assessment with partners using updated web framework, assessment, and analysis tools\n",
    "\n",
    "  * Perform Rasch analysis on second round of data to identify assessment items to review\n",
    "\n",
    "  * Alter problematic items as needed\n",
    "\n",
    "  * Revalidate assessment with student and faculty as needed\n",
    "\n",
    "  * Continue to identify partners\n",
    "\n",
    "  * Develop tools for cross-institutional and demographic analysis\n",
    "\n",
    "  * Begin preliminary investigation of cross-institutional and demographic effects\n",
    "\n",
    "\n",
    "## Project Timeline\n",
    "\n",
    "* **Semester 6:**\n",
    "\n",
    "  * Launch near final assessment with partners using updated web framework, assessment, and analysis tools\n",
    "\n",
    "  * Perform Rasch analysis on second round of data to identify assessment items to review\n",
    "\n",
    "  * Alter problematic items as needed\n",
    "\n",
    "  * Revalidate assessment with student and faculty as needed\n",
    "\n",
    "  * Perform cross-institutional and demographic analyses\n",
    "\n",
    "  * **Finalized assessment completed by end of semester**\n",
    "\n",
    "\n",
    "## Proposed Project Resources\n",
    "\n",
    "* Danny Caballero\n",
    "\n",
    "* Postdoc (to lead on project - need PER background)\n",
    "\n",
    "* PhD student 1 (PER with qualitative emphasis) - Dissertation: Categories of faculty's computational goals and student computational understandings for course X\n",
    "\n",
    "* PhD student 2 (PER with quantitative emphasis) - Dissertation: Development of assessment of students' computational understanding in course X\n",
    "\n",
    "* Master's students (PER, Computational, Web) - Projects: Development and deployment of analysis tools, web framework, testing usability, etc."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
